services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  kafka1:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka1
    container_name: kafka1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://${KAFKA_EXTERNAL_IP:-localhost}:${KAFKA_PORT_BASE:-909}2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  kafka2:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka2
    container_name: kafka2
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29093,PLAINTEXT_HOST://${KAFKA_EXTERNAL_IP:-localhost}:${KAFKA_PORT_BASE:-909}3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  kafka3:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka3
    container_name: kafka3
    depends_on:
      - zookeeper
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:29094,PLAINTEXT_HOST://${KAFKA_EXTERNAL_IP:-localhost}:${KAFKA_PORT_BASE:-909}4
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "${KAFKA_UI_PORT:-8081}:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:29092,kafka2:29093,kafka3:29094
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  logstash:
    image: docker.elastic.co/logstash/logstash:8.14.0
    container_name: logstash
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    volumes:
      - ./pipeline_index:/usr/share/logstash/pipeline:ro
    environment:
      LS_JAVA_OPTS: "-Xmx${LOGSTASH_HEAP_SIZE:-2g} -Xms${LOGSTASH_HEAP_SIZE:-2g} -XX:+UseG1GC -XX:MaxGCPauseMillis=50"
      PIPELINE_WORKERS: ${LOGSTASH_PIPELINE_WORKERS:-1}
      PIPELINE_BATCH_SIZE: ${LOGSTASH_BATCH_SIZE:-1}
      PIPELINE_BATCH_DELAY: ${LOGSTASH_BATCH_DELAY:-1}
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  logstash-storage:
    image: docker.elastic.co/logstash/logstash:8.14.0
    container_name: logstash-storage
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "5045:5044"
      - "${LOGSTASH_MONITORING_PORT:-9601}:9600"
    volumes:
      - ./pipeline_storage:/usr/share/logstash/pipeline:ro
    environment:
      LS_JAVA_OPTS: "-Xmx${LOGSTASH_HEAP_SIZE:-2g} -Xms${LOGSTASH_HEAP_SIZE:-2g} -XX:+UseG1GC -XX:MaxGCPauseMillis=50"
      PIPELINE_WORKERS: ${LOGSTASH_PIPELINE_WORKERS:-1}
      PIPELINE_BATCH_SIZE: ${LOGSTASH_BATCH_SIZE:-1}
      PIPELINE_BATCH_DELAY: ${LOGSTASH_BATCH_DELAY:-1}
    logging:
      driver: "json-file"
      options:
        max-size: "100m"  # Limite chaque fichier de log Ã  100MB
        max-file: "3"     # Garde maximum 3 fichiers (300MB total max)

  kafka-setup:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka-setup
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...'
        
        until kafka-broker-api-versions --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 > /dev/null 2>&1; do
          echo 'Waiting for Kafka cluster...'
          sleep 5
        done
        
        echo 'All Kafka brokers are ready!'
        
        kafka-topics --create --if-not-exists --topic ${KAFKA_TOPIC_RAW_DATA:-Emotibit_rawdata} --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 --partitions 3 --replication-factor 3 --config min.insync.replicas=2 --config flush.messages=1 --config flush.ms=1000 --config segment.ms=60000 --config retention.ms=86400000
        
        kafka-topics --create --if-not-exists --topic ${KAFKA_TOPIC_PROCESSED_DATA:-Emotibit_processdata} --bootstrap-server kafka1:29092,kafka2:29093,kafka3:29094 --partitions 3 --replication-factor 3 --config min.insync.replicas=2 --config flush.messages=1 --config flush.ms=1000 --config segment.ms=60000 --config retention.ms=86400000
        
        echo 'Topics ${KAFKA_TOPIC_RAW_DATA:-Emotibit_rawdata} and ${KAFKA_TOPIC_PROCESSED_DATA:-Emotibit_processdata} configured for real-time processing!'
        
        kafka-topics --describe --topic ${KAFKA_TOPIC_RAW_DATA:-Emotibit_rawdata} --bootstrap-server kafka1:29092
        kafka-topics --describe --topic ${KAFKA_TOPIC_PROCESSED_DATA:-Emotibit_processdata} --bootstrap-server kafka1:29092
        "
    restart: "no"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"